{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a58513",
   "metadata": {},
   "source": [
    "# PLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135092f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n",
      "I felt compelled to write a review for Space Cobra as it has received a good score of 7.3 stars but only a few of the reviews at the time of me writing this were particularly positive. A strange situation and hopefully my positive review will point people towards this old and mostly forgotten Anime movie. Space cobra is the funky tale of a smuggler and rogue who becomes involved with the three sisters of an ancient and dead planet and an evil force who wants to harness the planets powers. This is an old movie and the animation shows,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Function to read and clean data for one review\n",
    "def process_file(file_path, label):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        review_text = file.read()\n",
    "    return review_text, label\n",
    "\n",
    "# Function to read the data in parallel\n",
    "def load_data(data_dir):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    tasks = []\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for label_type in ['pos', 'neg']:\n",
    "            \n",
    "            dir_name = os.path.join(data_dir, label_type)\n",
    "            label = 1 if label_type == 'pos' else 0\n",
    "            \n",
    "            for file_name in os.listdir(dir_name):\n",
    "                file_path = os.path.join(dir_name, file_name)\n",
    "                # Submit tasks to process files in parallel\n",
    "                tasks.append(executor.submit(process_file, file_path, label))\n",
    "        \n",
    "        # Collect results as tasks complete\n",
    "        for task in as_completed(tasks):\n",
    "            review, label = task.result()\n",
    "            reviews.append(review)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return reviews, labels\n",
    "\n",
    "# Load train and test datasets\n",
    "train_reviews, train_labels = load_data('train')\n",
    "test_reviews, test_labels = load_data('test')\n",
    "\n",
    "# View an example of a review\n",
    "print(f\"Label: {train_labels[0]}\")\n",
    "print(\" \".join(train_reviews[0].split()[:100])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41119fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Initialize DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize the datasets\n",
    "def tokenize_data(reviews, labels):\n",
    "    encoding = tokenizer(reviews, padding=True, truncation=True, max_length=250, return_tensors='pt')\n",
    "    labels = torch.tensor(labels)\n",
    "    return TensorDataset(encoding['input_ids'], encoding['attention_mask'], labels)\n",
    "\n",
    "train_dataset = tokenize_data(train_reviews, train_labels)\n",
    "test_dataset = tokenize_data(test_reviews, test_labels)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Load pre-trained DistilBERT model for sequence classification\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "epochs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c05c0b1-fdab-4455-ac53-d21fcb07f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, optimizer, epochs):\n",
    "    model.train()\n",
    "    loss_values = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids, attention_mask, labels = [item for item in batch]\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        loss_values.append(avg_loss)\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {avg_loss}')\n",
    "\n",
    "    # Plotting the Training Convergence Plot\n",
    "    plt.plot(range(1, len(loss_values) + 1), loss_values)\n",
    "    plt.title('Training Loss Convergence')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26826e1-ac55-420c-8111-04913540e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids, attention_mask, labels = [item for item in batch]\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(softmax(logits, dim=1), dim=1)\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8080c313-9c2a-4c76-81e8-ca651b931d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34255a0-6298-4980-bea1-63d7b1af2511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e4384-2105-4e8f-bce6-6f474304d26d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a983552-e398-4311-9aa3-b533a0f136b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
